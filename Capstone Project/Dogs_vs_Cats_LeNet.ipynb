{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity Machine Learning Capstone Project\n",
    "## Dogs vs. Cats Redux - Kaggle Compeition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules imported.\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import pickle\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import resample\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Load the modules\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from resizeimage import resizeimage\n",
    "\n",
    "\n",
    "print('All modules imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a function to resize the image to desired dimension\n",
    "def resize_image(img, size):\n",
    "    \"\"\"\n",
    "    Resize PIL image\n",
    "    \n",
    "    Resizes image to be square with sidelength size. Pads with black if needed.\n",
    "    \"\"\"\n",
    "    # Resize\n",
    "    n_x, n_y = img.size\n",
    "    if n_y > n_x:\n",
    "        n_y_new = size\n",
    "        n_x_new = int(size * n_x / n_y + 0.5)\n",
    "    else:\n",
    "        n_x_new = size\n",
    "        n_y_new = int(size * n_y / n_x + 0.5)\n",
    "\n",
    "    img_res = img.resize((n_x_new, n_y_new), resample=Image.ANTIALIAS)\n",
    "\n",
    "    # Pad the borders to create a square image\n",
    "    img_pad = Image.new('RGB', (size, size), (128, 128, 128))\n",
    "    #img_pad = Image.new('L', (size, size))\n",
    "    ulc = ((size - n_x_new) // 2, (size - n_y_new) // 2)\n",
    "    img_pad.paste(img_res, ulc)\n",
    "\n",
    "    return img_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SIZE = 32\n",
    "\n",
    "# Unzip, load images and return feature and labels\n",
    "def uncompress_features_labels(file):\n",
    "    \"\"\"\n",
    "    Uncompress features and labels from a zip file\n",
    "    :param file: The zip file to extract the data from\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    with ZipFile(file) as zipf:\n",
    "        # Progress Bar\n",
    "        filenames_pbar = tqdm(zipf.namelist(), unit='files')\n",
    "        \n",
    "        # Get features and labels from all files\n",
    "        for filename in filenames_pbar:\n",
    "            # Check if the file is a directory\n",
    "            if not filename.endswith('/'):\n",
    "                with zipf.open(filename) as image_file:\n",
    "                    image = Image.open(image_file)\n",
    "                    image.load()\n",
    "                    img = resize_image(image, SIZE)\n",
    "                    feature = np.array(img, dtype=np.float32)\n",
    "                # Get the the letter from the filename.  This is the letter of the image.\n",
    "                label = os.path.split(filename)[1][0:3]\n",
    "                features.append(feature)\n",
    "                labels.append(label)\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Get the features and labels from the zip files\n",
    "X_train, y_train_string = uncompress_features_labels('train_sub.zip')\n",
    "# Wait until you see that all features and labels have been uncompressed.\n",
    "print('All features and labels uncompressed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Implement Min-Max scaling for grayscale image data\n",
    "# def normalize_grayscale(image_data):\n",
    "#     \"\"\"\n",
    "#     Normalize the image data with Min-Max scaling to a range of [0.1, 0.9]\n",
    "#     :param image_data: The image data to be normalized\n",
    "#     :return: Normalized image data\n",
    "#     \"\"\"\n",
    "#     # TODO: Implement Min-Max scaling for grayscale image data\n",
    "#     a = 0.1\n",
    "#     b = 0.9\n",
    "#     grayscale_min = 0\n",
    "#     grayscale_max = 255\n",
    "#     return a + ((image_data - grayscale_min)*(b-a))/(grayscale_max - grayscale_min)\n",
    "\n",
    "# X_train = normalize_grayscale(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Turn labels into numbers and apply One-Hot Encoding\n",
    "labels = []\n",
    "for item in y_train_string:\n",
    "    if item == 'cat':\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "        \n",
    "y_train = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get randomized datasets for training and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=0)\n",
    "\n",
    "print('Training features and labels randomized and split.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Training size is: {}'.format(len(X_train)))\n",
    "print('Validation size is: {}'.format(len(X_val))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Updated Image Shape: {}'.format(X_train[0].shape))\n",
    "index = random.randint(0, len(X_train))\n",
    "image = X_train[index].squeeze()\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(image)\n",
    "print(y_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the data for easy access\n",
    "pickle_file = 'DogCat_{0}px.pickle'.format(SIZE)\n",
    "if not os.path.isfile(pickle_file):\n",
    "    print('Saving data to pickle file...')\n",
    "    try:\n",
    "        with open(pickle_file, 'wb') as pfile:\n",
    "            pickle.dump(\n",
    "                {\n",
    "                    'train_dataset': X_train,\n",
    "                    'train_labels': y_train,\n",
    "                    'valid_dataset': X_val,\n",
    "                    'valid_labels': y_val,\n",
    "                },\n",
    "                pfile)\n",
    "    except Exception as e:\n",
    "        print('Unable to save data to', pickle_file, ':', e)\n",
    "        raise\n",
    "\n",
    "print('Data cached in pickle file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data and modules loaded.\n"
     ]
    }
   ],
   "source": [
    "SIZE = 32\n",
    "\n",
    "# Reload the data\n",
    "pickle_file = 'DogCat_{0}px.pickle'.format(SIZE)\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  pickle_data = pickle.load(f)\n",
    "  X_train = pickle_data['train_dataset']\n",
    "  y_train = pickle_data['train_labels']\n",
    "  X_val = pickle_data['valid_dataset']\n",
    "  y_val = pickle_data['valid_labels']\n",
    "  del pickle_data  # Free up memory\n",
    "    \n",
    "print('Data and modules loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800, 32, 32, 3)\n",
      "(1200, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement LeNet-5 as Baseline in TensorFlow\n",
    "\n",
    "### Input\n",
    "The LeNet architecture accepts a 32x32xC image as input, where C is the number of color channels. C is 3 in this case.\n",
    "\n",
    "### Architecture\n",
    "**Layer 1: Convolutional.** The output shape should be 28x28x6.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Pooling.** The output shape should be 14x14x6.\n",
    "\n",
    "**Layer 2: Convolutional.** The output shape should be 10x10x16.\n",
    "\n",
    "**Activation.** Your choice of activation function.\n",
    "\n",
    "**Pooling.** The output shape should be 5x5x16.\n",
    "\n",
    "**Flatten.** Flatten the output shape of the final pooling layer such that it's 1D instead of 3D. The easiest way to do is by using `tf.contrib.layers.flatten`\n",
    "\n",
    "**Layer 3: Fully Connected.** This should have 120 outputs.\n",
    "\n",
    "**Activation.** Relu\n",
    "\n",
    "**Layer 4: Fully Connected.** This should have 84 outputs.\n",
    "\n",
    "**Activation.** Relu\n",
    "\n",
    "**Layer 5: Fully Connected (Logits).** This should have 3 outputs.\n",
    "\n",
    "### Output\n",
    "Return the result of the 2nd fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def LeNet(x):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0.0\n",
    "    sigma = 1.0\n",
    "    weights = {\n",
    "        'wc1': tf.Variable(tf.truncated_normal((5, 5, 3, 6), mean = mu, stddev = sigma)),\n",
    "        'wc2': tf.Variable(tf.truncated_normal((5, 5, 6, 16), mean = mu, stddev = sigma)),\n",
    "        'wf1': tf.Variable(tf.truncated_normal((400, 120), mean = mu, stddev = sigma)),\n",
    "        'wf2': tf.Variable(tf.truncated_normal((120, 84), mean = mu, stddev = sigma)),\n",
    "        'wf3': tf.Variable(tf.truncated_normal((84, 2), mean = mu, stddev = sigma))\n",
    "    }\n",
    "    \n",
    "    biases = {\n",
    "        'bc1': tf.Variable(tf.zeros(6)),\n",
    "        'bc2': tf.Variable(tf.zeros(16)),\n",
    "        'bf1': tf.Variable(tf.zeros(120)),\n",
    "        'bf2': tf.Variable(tf.zeros(84)),\n",
    "        'bf3': tf.Variable(tf.zeros(2))\n",
    "    }\n",
    "    # TODO: Layer 1: Convolutional. Input = 32x32x3. Output = 28x28x6.\n",
    "    conv_layer1 = tf.nn.conv2d(x, weights['wc1'], strides = [1, 1, 1, 1], padding = 'VALID')\n",
    "    conv_layer1 = tf.nn.bias_add(conv_layer1, biases['bc1'])\n",
    "    # TODO: Activation.\n",
    "    conv_layer1 = tf.nn.relu(conv_layer1)\n",
    "    # TODO: Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    conv_layer1 = tf.nn.max_pool(conv_layer1, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'VALID')\n",
    "    \n",
    "    # TODO: Layer 2: Convolutional. Output = 10x10x16.\n",
    "    conv_layer2 = tf.nn.conv2d(conv_layer1, weights['wc2'], strides = [1, 1, 1, 1], padding = 'VALID')\n",
    "    conv_layer2 = tf.nn.bias_add(conv_layer2, biases['bc2'])\n",
    "    \n",
    "    # TODO: Activation.\n",
    "    conv_layer2 = tf.nn.relu(conv_layer2)\n",
    "    # TODO: Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    conv_layer2 = tf.nn.max_pool(conv_layer2, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'VALID')\n",
    "\n",
    "    # TODO: Flatten. Input = 5x5x16. Output = 400.\n",
    "    fc0 = flatten(conv_layer2)\n",
    "    \n",
    "    # TODO: Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "    fc1 = tf.add(tf.matmul(fc0, weights['wf1']), biases['bf1'])\n",
    "    # TODO: Activation.\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    \n",
    "    # TODO: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    fc2 = tf.add(tf.matmul(fc1, weights['wf2']), biases['bf2'])\n",
    "\n",
    "    # TODO: Activation.\n",
    "    fc2 = tf.nn.relu(fc2)\n",
    "\n",
    "    # TODO: Layer 5: Fully Connected. Input = 84. Output = 2.\n",
    "    fc3 = tf.add(tf.matmul(fc2, weights['wf3']), biases['bf3'])\n",
    "    logits = fc3\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, (None, SIZE, SIZE, 3))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "rate = 0.001\n",
    "\n",
    "logits = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits, one_hot_y)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "Evaluate how well the loss and accuracy of the model for a given dataset.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "Run the training data through the training pipeline to train the model.\n",
    "\n",
    "Before each epoch, shuffle the training set.\n",
    "\n",
    "After each epoch, measure the loss and accuracy of the validation set.\n",
    "\n",
    "Save the model after training.\n",
    "\n",
    "You do not need to modify this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.557\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.553\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.534\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.535\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.534\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.544\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.539\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.545\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.558\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.557\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})\n",
    "            \n",
    "        validation_accuracy = evaluate(X_val, y_val)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './DogsCats_lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "Epoch  1/10:   0%|          | 0/38 [00:00<?, ?batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Epoch  1/10: 100%|██████████| 38/38 [00:06<00:00,  5.90batches/s]\n",
      "Epoch  2/10: 100%|██████████| 38/38 [00:06<00:00,  5.66batches/s]\n",
      "Epoch  3/10: 100%|██████████| 38/38 [00:07<00:00,  4.97batches/s]\n",
      "Epoch  4/10: 100%|██████████| 38/38 [00:06<00:00,  6.01batches/s]\n",
      "Epoch  5/10: 100%|██████████| 38/38 [00:06<00:00,  6.31batches/s]\n",
      "Epoch  6/10: 100%|██████████| 38/38 [00:05<00:00,  6.50batches/s]\n",
      "Epoch  7/10: 100%|██████████| 38/38 [00:06<00:00,  6.25batches/s]\n",
      "Epoch  8/10: 100%|██████████| 38/38 [00:05<00:00,  6.44batches/s]\n",
      "Epoch  9/10: 100%|██████████| 38/38 [00:06<00:00,  5.98batches/s]\n",
      "Epoch 10/10: 100%|██████████| 38/38 [00:06<00:00,  5.99batches/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGWOM8aT/D/OFnaOxdnkWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f030518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Measurements use for graphing loss and accuracy\n",
    "log_batch_step = 50\n",
    "batches = []\n",
    "loss_batch = []\n",
    "train_acc_batch = []\n",
    "valid_acc_batch = []\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    batch_count = int(math.ceil(num_examples/BATCH_SIZE))\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        X_val, y_val = shuffle(X_val, y_val)\n",
    "        # Progress bar\n",
    "        batches_pbar = tqdm(range(batch_count), desc='Epoch {:>2}/{}'.format(i+1, EPOCHS), unit='batches')\n",
    "        \n",
    "         # The training cycle\n",
    "        for batch_i in batches_pbar:\n",
    "            # Get a batch of training features and labels\n",
    "            batch_start = batch_i*BATCH_SIZE\n",
    "            batch_features = X_train[batch_start:batch_start + BATCH_SIZE]\n",
    "            batch_labels = y_train[batch_start:batch_start + BATCH_SIZE]\n",
    "\n",
    "            # Run optimizer and get loss\n",
    "            _, l = sess.run(\n",
    "                [training_operation, loss_operation],\n",
    "                feed_dict={x: batch_features, y: batch_labels})\n",
    "\n",
    "            # Log every 50 batches\n",
    "            if not batch_i % log_batch_step:\n",
    "                # Calculate Training and Validation accuracy\n",
    "                training_accuracy = sess.run(accuracy_operation, feed_dict={x: X_train, y: y_train})\n",
    "                validation_accuracy = sess.run(accuracy_operation, feed_dict={x: X_val, y: y_val})\n",
    "\n",
    "                # Log batches\n",
    "                previous_batch = batches[-1] if batches else 0\n",
    "                batches.append(log_batch_step + previous_batch)\n",
    "                loss_batch.append(l)\n",
    "                train_acc_batch.append(training_accuracy)\n",
    "                valid_acc_batch.append(validation_accuracy)\n",
    "    saver.save(sess, './DogsCats_lenet2')\n",
    "    print(\"Model saved\")\n",
    "    \n",
    "loss_plot = plt.subplot(211)\n",
    "loss_plot.set_title('Loss')\n",
    "loss_plot.plot(batches, loss_batch, 'g')\n",
    "loss_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot = plt.subplot(212)\n",
    "acc_plot.set_title('Accuracy')\n",
    "acc_plot.plot(batches, train_acc_batch, 'r', label='Training Accuracy')\n",
    "acc_plot.plot(batches, valid_acc_batch, 'x', label='Validation Accuracy')\n",
    "acc_plot.set_ylim([0, 1.0])\n",
    "acc_plot.set_xlim([batches[0], batches[-1]])\n",
    "acc_plot.legend(loc=4)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
